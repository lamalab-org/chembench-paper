\begin{tabular}{lcccc}
\toprule
\multirow{3}{*}{Model} & \multicolumn{2}{c}{\textbf{Refusal}} & \multicolumn{2}{c}{\textbf{LLM Extraction}}\\
\cmidrule(lr){2-3} \cmidrule(lr){4-5}\\
& Nº of Questions & Fraction & Nº of Questions & Fraction\\
\midrule
Claude 2 & 100 & 0.035868 & 0 & 0.000000 \\
Claude 3 & 9 & 0.003228 & 0 & 0.000000 \\
Claude 3.5 Sonnet & 31 & 0.011119 & 3 & 0.001076 \\
Claude-3.5 ReAct & 0 & 0.000000 & 129 & 0.046270 \\
Command R+ & 0 & 0.000000 & 5 & 0.001793 \\
Gemini Pro & 0 & 0.000000 & 4 & 0.001435 \\
Gemma 1.1 7B & 0 & 0.000000 & 18 & 0.006456 \\
Gemma 1.1 7B Temp=1 & 1 & 0.000359 & 22 & 0.007891 \\
Gemma 2 9B & 5 & 0.001793 & 25 & 0.008967 \\
Gemma 2 9B Temp=1 & 5 & 0.001793 & 37 & 0.013271 \\
GPT-3.5 Turbo & 0 & 0.000000 & 8 & 0.002869 \\
GPT-4 & 0 & 0.000000 & 3 & 0.001076 \\
GPT-4o & 0 & 0.000000 & 7 & 0.002511 \\
GPT-4o ReAct & 0 & 0.000000 & 667 & 0.239240 \\
Llama 2 70B Chat & 1 & 0.000359 & 3 & 0.001076 \\
Llama 3 70B & 0 & 0.000000 & 16 & 0.005739 \\
Llama 3 70B Temp=1 & 1 & 0.000359 & 17 & 0.006098 \\
Llama 3 8B & 0 & 0.000000 & 9 & 0.003228 \\
Llama 3 8B Temp=1 & 6 & 0.002152 & 11 & 0.003945 \\
Llama 3.1 405B & 0 & 0.000000 & 22 & 0.007891 \\
Llama 3.1 70B & 0 & 0.000000 & 53 & 0.019010 \\
Llama 3.1 70B Temp=1 & 1 & 0.000359 & 245 & 0.087877 \\
Llama 3.1 8B & 0 & 0.000000 & 35 & 0.012554 \\
Llama 3.1 8B Temp=1 & 3 & 0.001076 & 30 & 0.010760 \\
Mistral Large 2 123B & 0 & 0.000000 & 2 & 0.000717 \\
Mixtral 8x7B & 4 & 0.001435 & 54 & 0.019369 \\
Mixtral 8x7B Temp=1 & 7 & 0.002511 & 58 & 0.020803 \\
o1 & 0 & 0.000000 & 2 & 0.000717 \\
Paper QA & 35 & 0.012554 & 52 & 0.018651 \\
Phi 3 Medium 4K & 0 & 0.000000 & 7 & 0.002511 \\
\bottomrule
\end{tabular}
