\begin{table}[htbp]\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{cccccccc}
\toprule
\multirow{3}{*}{Model} & \multicolumn{3}{c}{\textbf{Requires}} & \multicolumn{3}{c}{\textbf{Difficulty}} & \multirow{3}{*}{\textbf{Overall Accuracy}}\\\cmidrule(lr){2-4} \cmidrule(lr){5-7}\\
 & Calculation & Knowledge & Reasoning & Basic & Intermediate & Advanced &  \\
\midrule
Mistral Large 2 123B & 0.66 & 0.6 & 0.66 & 0.71 & 0.61 & 0.55 & 0.65 \\
Mixtral 8x7B & 0.23 & 0.37 & 0.36 & 0.44 & 0.29 & 0.23 & 0.35 \\
Llama 3 70B & 0.49 & 0.58 & 0.55 & 0.66 & 0.55 & 0.27 & 0.57 \\
Llama 3.1 405B & 0.66 & 0.64 & 0.67 & 0.72 & 0.65 & 0.5 & 0.66 \\
Paper QA & 0.63 & 0.64 & 0.62 & 0.69 & 0.62 & 0.5 & 0.64 \\
GPT-4o & 0.68 & 0.66 & 0.71 & 0.8 & 0.62 & 0.59 & 0.69 \\
Gemma 2 9B & 0.44 & 0.43 & 0.43 & 0.56 & 0.41 & 0.36 & 0.46 \\
Llama 3.1 70B & 0.52 & 0.57 & 0.61 & 0.72 & 0.57 & 0.32 & 0.61 \\
Command R+ & 0.25 & 0.45 & 0.39 & 0.45 & 0.4 & 0.18 & 0.4 \\
GPT-3.5-Turbo & 0.31 & 0.42 & 0.43 & 0.5 & 0.38 & 0.31 & 0.42 \\
Phi 3 Medium 4K & 0.34 & 0.45 & 0.5 & 0.57 & 0.44 & 0.44 & 0.49 \\
Claude 2 & 0.29 & 0.48 & 0.49 & 0.57 & 0.42 & 0.31 & 0.47 \\
Claude 3 & 0.62 & 0.59 & 0.64 & 0.77 & 0.58 & 0.38 & 0.63 \\
Random Baseline & 0.12 & 0.11 & 0.16 & 0.18 & 0.14 & 0.05 & 0.15 \\
OpenAI o1 & \textbf{0.77} & \textbf{0.73} & \textbf{0.78} & \textbf{0.81} & \textbf{0.71} & \textbf{0.77} & \textbf{0.76} \\
Llama 3 8B & 0.26 & 0.5 & 0.44 & 0.42 & 0.43 & 0.45 & 0.43 \\
Llama 2 70B Chat & 0.12 & 0.17 & 0.12 & 0.19 & 0.12 & 0 & 0.14 \\
Gemini Pro & 0.27 & 0.45 & 0.45 & 0.49 & 0.4 & 0.32 & 0.43 \\
Llama 3.1 8B & 0.33 & 0.44 & 0.42 & 0.55 & 0.36 & 0.36 & 0.44 \\
Claude 3.5 Sonnet & 0.62 & 0.68 & 0.72 & 0.8 & 0.65 & 0.56 & 0.7 \\
Galactica 120B & 0.01 & 0.02 & 0.01 & 0.04 & 0.01 & 0 & 0.02 \\
Gemma 1.1 7B & 0.23 & 0.37 & 0.34 & 0.41 & 0.32 & 0.09 & 0.33 \\
GPT-4 & 0.47 & 0.58 & 0.62 & 0.66 & 0.58 & 0.5 & 0.6 \\
\bottomrule
\end{tabular}

}
\end{table}