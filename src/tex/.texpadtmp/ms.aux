\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\abx@aux@refcontext{none/global//global/global}
\HyPL@Entry{0<</S/D>>}
\providecommand\@newglossary[4]{}
\@newglossary{main}{glg}{gls}{glo}
\@newglossary{acronym}{alg}{acr}{acn}
\babel@aux{english}{}
\providecommand\@gls@reference[3]{}
\abx@aux@refsection{1}{3}
\abx@aux@cite{1}{brown2020language}
\abx@aux@segm{1}{0}{brown2020language}
\abx@aux@cite{1}{zhong2024benchmarking}
\abx@aux@segm{1}{0}{zhong2024benchmarking}
\abx@aux@cite{1}{kung2023performance}
\abx@aux@segm{1}{0}{kung2023performance}
\abx@aux@cite{1}{openai2024gpt4}
\abx@aux@segm{1}{0}{openai2024gpt4}
\abx@aux@cite{1}{Boiko_2023}
\abx@aux@segm{1}{0}{Boiko_2023}
\abx@aux@cite{1}{bran2023chemcrow}
\abx@aux@segm{1}{0}{bran2023chemcrow}
\abx@aux@cite{1}{bubeck2023sparks}
\abx@aux@segm{1}{0}{bubeck2023sparks}
\abx@aux@cite{1}{bender2021dangers}
\abx@aux@segm{1}{0}{bender2021dangers}
\abx@aux@cite{1}{bommasani2021opportunities}
\abx@aux@segm{1}{0}{bommasani2021opportunities}
\abx@aux@cite{1}{anderljung2023frontier}
\abx@aux@segm{1}{0}{anderljung2023frontier}
\abx@aux@cite{1}{bloomberg}
\abx@aux@segm{1}{0}{bloomberg}
\abx@aux@cite{1}{White_2023}
\abx@aux@segm{1}{0}{White_2023}
\abx@aux@cite{1}{jablonka202314}
\abx@aux@segm{1}{0}{jablonka202314}
\abx@aux@cite{1}{jablonka2024leveraging}
\abx@aux@segm{1}{0}{jablonka2024leveraging}
\abx@aux@cite{1}{xie2024fine}
\abx@aux@segm{1}{0}{xie2024fine}
\abx@aux@cite{1}{liao2024words}
\abx@aux@segm{1}{0}{liao2024words}
\abx@aux@cite{1}{zhang2024chemllm}
\abx@aux@segm{1}{0}{zhang2024chemllm}
\abx@aux@cite{1}{zhong2024benchmarking}
\abx@aux@segm{1}{0}{zhong2024benchmarking}
\abx@aux@cite{1}{ramos2023bayesian}
\abx@aux@segm{1}{0}{ramos2023bayesian}
\abx@aux@cite{1}{kristiadi2024sober}
\abx@aux@segm{1}{0}{kristiadi2024sober}
\abx@aux@cite{1}{rubungo2023llm}
\abx@aux@segm{1}{0}{rubungo2023llm}
\abx@aux@cite{1}{flam2023language}
\abx@aux@segm{1}{0}{flam2023language}
\abx@aux@cite{1}{gruver2024fine}
\abx@aux@segm{1}{0}{gruver2024fine}
\abx@aux@cite{1}{Patiny_2023}
\abx@aux@segm{1}{0}{Patiny_2023}
\abx@aux@cite{1}{Dagdelen_2024}
\abx@aux@segm{1}{0}{Dagdelen_2024}
\abx@aux@cite{1}{Zheng_2024}
\abx@aux@segm{1}{0}{Zheng_2024}
\abx@aux@cite{1}{lala2023paperqa}
\abx@aux@segm{1}{0}{lala2023paperqa}
\abx@aux@cite{1}{caufield2023structured}
\abx@aux@segm{1}{0}{caufield2023structured}
\abx@aux@cite{1}{gupta2022discomat}
\abx@aux@segm{1}{0}{gupta2022discomat}
\abx@aux@cite{1}{bran2023chemcrow}
\abx@aux@segm{1}{0}{bran2023chemcrow}
\abx@aux@cite{1}{Boiko_2023}
\abx@aux@segm{1}{0}{Boiko_2023}
\abx@aux@cite{1}{darvish2024organa}
\abx@aux@segm{1}{0}{darvish2024organa}
\abx@aux@cite{1}{miret2024llms}
\abx@aux@segm{1}{0}{miret2024llms}
\abx@aux@cite{1}{Boiko_2023}
\abx@aux@segm{1}{0}{Boiko_2023}
\abx@aux@cite{1}{bran2023chemcrow}
\abx@aux@segm{1}{0}{bran2023chemcrow}
\abx@aux@cite{1}{darvish2024organa}
\abx@aux@segm{1}{0}{darvish2024organa}
\abx@aux@cite{1}{granda2018controlling}
\abx@aux@segm{1}{0}{granda2018controlling}
\abx@aux@cite{1}{Angello_2022}
\abx@aux@segm{1}{0}{Angello_2022}
\abx@aux@cite{1}{coley2019robotic}
\abx@aux@segm{1}{0}{coley2019robotic}
\abx@aux@cite{1}{Burger_2020}
\abx@aux@segm{1}{0}{Burger_2020}
\abx@aux@cite{1}{seifrid2022autonomous}
\abx@aux@segm{1}{0}{seifrid2022autonomous}
\abx@aux@cite{1}{gopal2023releasing}
\abx@aux@segm{1}{0}{gopal2023releasing}
\abx@aux@cite{1}{ganguli2022red}
\abx@aux@segm{1}{0}{ganguli2022red}
\abx@aux@cite{1}{Urbina_2022}
\abx@aux@segm{1}{0}{Urbina_2022}
\abx@aux@cite{1}{campbell2023censoring}
\abx@aux@segm{1}{0}{campbell2023censoring}
\abx@aux@cite{1}{moulange2023towards}
\abx@aux@segm{1}{0}{moulange2023towards}
\abx@aux@cite{1}{urbina2022teachable}
\abx@aux@segm{1}{0}{urbina2022teachable}
\abx@aux@cite{1}{Intelligent.com_2023}
\abx@aux@segm{1}{0}{Intelligent.com_2023}
\newlabel{refsection:1}{{}{3}{}{Doc-Start}{}}
\newlabel{refsection:1@cref}{{}{[1][3][]3}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{3}{section.1}\protected@file@percent }
\@gls@reference{acronym}{llm}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{3}}
\@gls@reference{acronym}{ml}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{3}}
\@gls@reference{acronym}{agi}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{3}}
\@gls@reference{acronym}{llm}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{3}}
\@gls@reference{acronym}{llm}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{3}}
\@gls@reference{acronym}{llm}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{3}}
\@gls@reference{acronym}{ml}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{3}}
\@gls@reference{acronym}{llm}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{3}}
\abx@aux@cite{1}{srivastava2022beyond}
\abx@aux@segm{1}{0}{srivastava2022beyond}
\abx@aux@cite{1}{eval-harness}
\abx@aux@segm{1}{0}{eval-harness}
\abx@aux@cite{1}{jablonka2024leveraging}
\abx@aux@segm{1}{0}{jablonka2024leveraging}
\abx@aux@cite{1}{guo2023large}
\abx@aux@segm{1}{0}{guo2023large}
\abx@aux@cite{1}{ahmad2022chemberta2}
\abx@aux@segm{1}{0}{ahmad2022chemberta2}
\abx@aux@cite{1}{Cai_2024}
\abx@aux@segm{1}{0}{Cai_2024}
\abx@aux@cite{1}{frey2023neural}
\abx@aux@segm{1}{0}{frey2023neural}
\abx@aux@cite{1}{dinh2022lift}
\abx@aux@segm{1}{0}{dinh2022lift}
\abx@aux@cite{1}{wu2018moleculenet}
\abx@aux@segm{1}{0}{wu2018moleculenet}
\abx@aux@cite{1}{huang2021therapeutics}
\abx@aux@segm{1}{0}{huang2021therapeutics}
\abx@aux@cite{1}{Dunn_2020}
\abx@aux@segm{1}{0}{Dunn_2020}
\abx@aux@cite{1}{Zaki_2024}
\abx@aux@segm{1}{0}{Zaki_2024}
\abx@aux@cite{1}{arora2023llms}
\abx@aux@segm{1}{0}{arora2023llms}
\abx@aux@cite{1}{song2023honeybee}
\abx@aux@segm{1}{0}{song2023honeybee}
\abx@aux@cite{1}{wei2021chemistryqa}
\abx@aux@segm{1}{0}{wei2021chemistryqa}
\abx@aux@cite{1}{song-etal-2023-matsci}
\abx@aux@segm{1}{0}{song-etal-2023-matsci}
\@gls@reference{acronym}{llm}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{4}}
\@gls@reference{acronym}{llm}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{4}}
\@gls@reference{acronym}{llm}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{4}}
\@gls@reference{acronym}{llm}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{4}}
\@gls@reference{acronym}{llm}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \textbf  {Overview of the ChemBench\xspace  framework.} The figure shows the different components of the ChemBench\xspace  framework. The framework's foundation is the benchmark corpus that consists of many questions and answers that we manually or semi-automatically compiled from various sources. We then used this corpus to evaluate the performance of various models and tool-augmented systems using a custom framework. To provide a baseline, we built a web application that we used to survey experts in chemistry. The results of the evaluations are then compiled in publicly accessible leaderboards, which we propose as a foundation for evaluating future models. \relax }}{5}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:overview_figure}{{1}{5}{\textbf {Overview of the \chembench framework.} The figure shows the different components of the \chembench framework. The framework's foundation is the benchmark corpus that consists of many questions and answers that we manually or semi-automatically compiled from various sources. We then used this corpus to evaluate the performance of various models and tool-augmented systems using a custom framework. To provide a baseline, we built a web application that we used to survey experts in chemistry. The results of the evaluations are then compiled in publicly accessible leaderboards, which we propose as a foundation for evaluating future models. \relax }{figure.caption.1}{}}
\newlabel{fig:overview_figure@cref}{{[figure][1][]1}{[1][5][]5}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Results and Discussion}{5}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Benchmark corpus}{5}{subsection.2.1}\protected@file@percent }
\@gls@reference{acronym}{pca}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{5}}
\abx@aux@cite{1}{bart}
\abx@aux@segm{1}{0}{bart}
\abx@aux@cite{1}{bart}
\abx@aux@segm{1}{0}{bart}
\abx@aux@cite{1}{polo2024tinybenchmarks}
\abx@aux@segm{1}{0}{polo2024tinybenchmarks}
\abx@aux@cite{1}{liang2023holistic}
\abx@aux@segm{1}{0}{liang2023holistic}
\abx@aux@cite{1}{taylor2022galactica}
\abx@aux@segm{1}{0}{taylor2022galactica}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \textbf  {Number of questions for different topics.} The topics have been assigned using a combination of a rule-based system (mostly based on the source the question has been sampled from) and a classifier operating on word embeddings of the questions. The figure shows that not all aspects of chemistry are equally represented in our corpus. The ChemBench\xspace  corpus, by design, currently focuses on safety-related aspects, which is also evident in \Cref  {fig:question_diversity}. This figure represents the combined count of \glstext {mcq} and open-ended questions.\relax }}{6}{figure.caption.2}\protected@file@percent }
\@gls@reference{acronym}{mcq}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{6}}
\newlabel{fig:topic_barplot}{{2}{6}{\textbf {Number of questions for different topics.} The topics have been assigned using a combination of a rule-based system (mostly based on the source the question has been sampled from) and a classifier operating on word embeddings of the questions. The figure shows that not all aspects of chemistry are equally represented in our corpus. The \chembench corpus, by design, currently focuses on safety-related aspects, which is also evident in \Cref {fig:question_diversity}. This figure represents the combined count of \glstext {mcq} and open-ended questions.\relax }{figure.caption.2}{}}
\newlabel{fig:topic_barplot@cref}{{[figure][2][]2}{[1][5][]6}}
\@gls@reference{acronym}{mcq}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{6}}
\@gls@reference{acronym}{mcq}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{6}}
\@gls@reference{acronym}{mcq}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{6}}
\@writefile{toc}{\contentsline {paragraph}{\enquote {Tiny} subset}{6}{section*.4}\protected@file@percent }
\@gls@reference{acronym}{api}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{6}}
\@gls@reference{acronym}{helm}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Model evaluation}{6}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Benchmark suite design}{6}{section*.5}\protected@file@percent }
\abx@aux@cite{1}{schick2024toolformer}
\abx@aux@segm{1}{0}{schick2024toolformer}
\abx@aux@cite{1}{karpas2022mrkl}
\abx@aux@segm{1}{0}{karpas2022mrkl}
\abx@aux@cite{1}{yao2022react}
\abx@aux@segm{1}{0}{yao2022react}
\abx@aux@cite{1}{Fourrier_Habib_Launay_Wolf}
\abx@aux@segm{1}{0}{Fourrier_Habib_Launay_Wolf}
\abx@aux@cite{1}{Huggingface}
\abx@aux@segm{1}{0}{Huggingface}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \textbf  {Principal component projection of embeddings of questions in the ChemBench\xspace  corpus.} To obtain this figure, we embedded questions and answers using the BART model\blx@tocontentsinit {1}\autocite {bart} (using other embeddings, such as of OpenAI's ada model, leads to qualitatively similar results). We then project the embeddings into a two-dimensional space using \gls {pca}. We color the points based on a classification into topics. Safety-related aspects cover a large part of the figure that is not covered by questions from other topics.\relax }}{7}{figure.caption.3}\protected@file@percent }
\@gls@reference{acronym}{pca}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{7}}
\newlabel{fig:question_diversity}{{3}{7}{\textbf {Principal component projection of embeddings of questions in the \chembench corpus.} To obtain this figure, we embedded questions and answers using the BART model\autocite {bart} (using other embeddings, such as of OpenAI's ada model, leads to qualitatively similar results). We then project the embeddings into a two-dimensional space using \gls {pca}. We color the points based on a classification into topics. Safety-related aspects cover a large part of the figure that is not covered by questions from other topics.\relax }{figure.caption.3}{}}
\newlabel{fig:question_diversity@cref}{{[figure][3][]3}{[1][6][]7}}
\@gls@reference{acronym}{smiles}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{7}}
\@gls@reference{acronym}{smiles}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{7}}
\@gls@reference{acronym}{llm}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{7}}
\@gls@reference{acronym}{api}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{7}}
\@gls@reference{acronym}{llm}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{7}}
\@writefile{toc}{\contentsline {paragraph}{System performance}{7}{section*.7}\protected@file@percent }
\@gls@reference{acronym}{llm}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces \textbf  {Performance of models and humans on the \enquote {tiny} subset of the ChemBench\xspace  corpus.} The figure shows the percentage of questions that the models answered completely correctly. We use horizontal bars to indicate the performance of various models and highlight statistics of the human performance. Since the humans did not answer all the questions, this plot is based on the subset of questions that most humans answered. The evaluation we use here is very strict as it only considers a question answered completely correctly or completely incorrectly, partially correct answers are also considered incorrect. \Cref  {fig:barplot_all_correct_all_questions} provides an overview of the performance of various models on the entire corpus. Systems with \enquote {ReAct} in the name are tool augmented, i.e., they can call external tools such as web search or Python code executors to better answer the questions. However, we limit those systems to a maximum of ten calls to the \gls {llm}. This constraint led the systems to often not find the correct answer within the specified number of calls. In this case, we consider the answer as incorrect. \relax }}{8}{figure.caption.6}\protected@file@percent }
\@gls@reference{acronym}{llm}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{8}}
\newlabel{fig:human_vs_models_bar}{{4}{8}{\textbf {Performance of models and humans on the \enquote {tiny} subset of the \chembench corpus.} The figure shows the percentage of questions that the models answered completely correctly. We use horizontal bars to indicate the performance of various models and highlight statistics of the human performance. Since the humans did not answer all the questions, this plot is based on the subset of questions that most humans answered. The evaluation we use here is very strict as it only considers a question answered completely correctly or completely incorrectly, partially correct answers are also considered incorrect. \Cref {fig:barplot_all_correct_all_questions} provides an overview of the performance of various models on the entire corpus. Systems with \enquote {ReAct} in the name are tool augmented, i.e., they can call external tools such as web search or Python code executors to better answer the questions. However, we limit those systems to a maximum of ten calls to the \gls {llm}. This constraint led the systems to often not find the correct answer within the specified number of calls. In this case, we consider the answer as incorrect. \relax }{figure.caption.6}{}}
\newlabel{fig:human_vs_models_bar@cref}{{[figure][4][]4}{[1][7][]8}}
\@gls@reference{acronym}{llm}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{8}}
\abx@aux@cite{1}{yao2022react}
\abx@aux@segm{1}{0}{yao2022react}
\abx@aux@cite{1}{berglund2023reversal}
\abx@aux@segm{1}{0}{berglund2023reversal}
\abx@aux@cite{1}{zhu2023physics}
\abx@aux@segm{1}{0}{zhu2023physics}
\abx@aux@cite{1}{allen2023physics}
\abx@aux@segm{1}{0}{allen2023physics}
\abx@aux@cite{1}{golovneva2024reverse}
\abx@aux@segm{1}{0}{golovneva2024reverse}
\@gls@reference{acronym}{llm}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{9}}
\@gls@reference{acronym}{llm}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{9}}
\@gls@reference{acronym}{api}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{9}}
\@writefile{toc}{\contentsline {paragraph}{Performance per topic}{9}{section*.8}\protected@file@percent }
\@gls@reference{acronym}{nmr}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{9}}
\@gls@reference{acronym}{smiles}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{9}}
\@gls@reference{acronym}{llm}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{10}}
\@gls@reference{acronym}{api}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces \textbf  {Performance of the models and humans on the different topics of the \enquote {tiny} subset of the ChemBench\xspace  corpus.} The radar plot shows the performance of the models and humans on the different topics of \enquote {tiny} subset of the ChemBench\xspace  corpus. The performance is measured as the fraction of questions that were answered completely correctly by the models. The best score for every dimension is one (all questions answered correctly), and the worst is zero (no question answered completely correctly). A larger colored area indicates a better performance. This figure shows the performance on the subset of questions that were answered by humans. The performance of models on the entire corpus is shown in \Cref  {fig:performance_per_topic}. \relax }}{11}{figure.caption.9}\protected@file@percent }
\newlabel{fig:all_questions_models_completely_correct_radar_human}{{5}{11}{\textbf {Performance of the models and humans on the different topics of the \enquote {tiny} subset of the \chembench corpus.} The radar plot shows the performance of the models and humans on the different topics of \enquote {tiny} subset of the \chembench corpus. The performance is measured as the fraction of questions that were answered completely correctly by the models. The best score for every dimension is one (all questions answered correctly), and the worst is zero (no question answered completely correctly). A larger colored area indicates a better performance. This figure shows the performance on the subset of questions that were answered by humans. The performance of models on the entire corpus is shown in \Cref {fig:performance_per_topic}. \relax }{figure.caption.9}{}}
\newlabel{fig:all_questions_models_completely_correct_radar_human@cref}{{[figure][5][]5}{[1][9][]11}}
\abx@aux@cite{1}{xiong2023llms}
\abx@aux@segm{1}{0}{xiong2023llms}
\abx@aux@cite{1}{Li_2023}
\abx@aux@segm{1}{0}{Li_2023}
\abx@aux@cite{1}{miret2024llms}
\abx@aux@segm{1}{0}{miret2024llms}
\@writefile{toc}{\contentsline {paragraph}{Confidence estimates}{12}{section*.10}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces \textbf  {Relationship between confidence of the model in the answer and correctness.} For this analysis, we used verbalized confidence estimates from the model. We prompted the models to return a confidence score on an ordinal scale to obtain those estimates. We then plot the correctness of the answers (which is calculated as the mean value of all answers being either completely correct (1) or completely incorrect (0)) against the confidence score. The stripplots show the individual data points, a strong density indicating a higher number of points. The lines show the mean, and the error bars show the standard error of the mean. The figure shows that the reliability of the confidence estimates varies widely across models. While the ones for GPT-4 and Claude 2 are not particularly reliable, the ones for Claude 3 follow the expected trend.\relax }}{12}{figure.caption.11}\protected@file@percent }
\newlabel{fig:confidence_vs_performance}{{6}{12}{\textbf {Relationship between confidence of the model in the answer and correctness.} For this analysis, we used verbalized confidence estimates from the model. We prompted the models to return a confidence score on an ordinal scale to obtain those estimates. We then plot the correctness of the answers (which is calculated as the mean value of all answers being either completely correct (1) or completely incorrect (0)) against the confidence score. The stripplots show the individual data points, a strong density indicating a higher number of points. The lines show the mean, and the error bars show the standard error of the mean. The figure shows that the reliability of the confidence estimates varies widely across models. While the ones for GPT-4 and Claude 2 are not particularly reliable, the ones for Claude 3 follow the expected trend.\relax }{figure.caption.11}{}}
\newlabel{fig:confidence_vs_performance@cref}{{[figure][6][]6}{[1][12][]12}}
\@gls@reference{acronym}{ghs}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{13}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Conclusions}{13}{section.3}\protected@file@percent }
\@gls@reference{acronym}{llm}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{13}}
\@gls@reference{acronym}{llm}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{13}}
\@gls@reference{acronym}{llm}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{13}}
\@gls@reference{acronym}{llm}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{13}}
\@gls@reference{acronym}{llm}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{13}}
\@gls@reference{acronym}{llm}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{13}}
\@gls@reference{acronym}{ml}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{13}}
\abx@aux@cite{1}{openai2024gpt4}
\abx@aux@segm{1}{0}{openai2024gpt4}
\abx@aux@cite{1}{srivastava2022beyond}
\abx@aux@segm{1}{0}{srivastava2022beyond}
